#读书笔记 


# 重整化


思想：

截断+标度->重整化


重整化方法：

动量空间重整化

$$
\phi(k) \rightarrow \phi(k) \eta(k / \Lambda)
$$

实空间重整化

$$
\tilde{\phi}(r) \rightarrow(\tilde{\eta} \star \tilde{\phi})(r)=\int_{r^{\prime}} \tilde{\phi}\left(r-r^{\prime}\right) \tilde{\eta}\left(r^{\prime} / R\right)
$$



## Ising模型重整化

$$
\begin{aligned}
P(\boldsymbol{\sigma}) &=\frac{1}{Z} e^{-H(\boldsymbol{\sigma})} \quad \multicolumn{1}{c} {Z=\sum_{\text {概率分布 }}} \\
\text { 配分函数 } & \sum_{\boldsymbol{\sigma}} e^{-H(\boldsymbol{\sigma})} \\
&=\frac{1}{Z} e^{J \sum_{\langle i j\rangle} \sigma_{i} \sigma_{j}}=\frac{1}{Z} \prod_{\langle i j\rangle} e^{J \sigma_{i} \sigma_{j}}
\end{aligned}
$$



$$
\text { 这里可以选择任何具有表象学习能力的生成型模型 }
$$
![[Pasted image 20210821094523.png]]$$
\begin{aligned}
&H_{\mathrm{loc}}(\boldsymbol{\sigma})=-J\left(\sigma_{0} \sigma_{1}+\sigma_{2} \sigma_{3}+\sigma_{0} \sigma_{2}+\sigma_{1} \sigma_{3}\right) \\
&P_{\mathrm{loc}}(\boldsymbol{\sigma})=Z_{\mathrm{loc}}^{-1} e^{-H_{\mathrm{loc}}(\boldsymbol{\sigma})}
\end{aligned}
$$


在重整化中，“不动点”不是参数，也不是模型，而是生成模型的模型。

![[Screenshot_2021-08-21 10.10.18_6s069L.png]]


### 全息重整化

传统重整化：
- 压缩映射
- 提取相关变量，丢弃无关变量
- 目标：压缩信息

而全息重整化：
- 可逆映射
- 提取相关变量，保留无关变量
- 目标：全息化



![[Screenshot_2021-08-21 10.48.02_Laz9nf.png]]


### 最小全息互信息原理

关于[[互信息]]

![[Screenshot_2021-08-21 10.55.52_fQCOqz.png]]

