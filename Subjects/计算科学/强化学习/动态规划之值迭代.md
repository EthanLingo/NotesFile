# 动态规划之值迭代


值迭代方法本质上是变更[[贝尔曼最优方程]]为一条更新规则。

值迭代结合了策略评估遍历与策略改进遍历。每次策略改进遍历中间进行多次策略评估遍历使得收敛更快。

#算法 算法之于值迭代
![[Pasted image 20211207212754.png]]

#公式 公式之于值改进
$$
\begin{aligned}
v_{k+1}(s) & \doteq \max _{a} \mathbb{E}\left[R_{t+1}+\gamma v_{k}\left(S_{t+1}\right) \mid S_{t}=s, A_{t}=a\right] \\
&=\max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid s, a\right)\left[r+\gamma v_{k}\left(s^{\prime}\right)\right]
\end{aligned}
$$