# 强化学习之离轨策略学习


      

> 所有的控制方法都会面临这样一个两难的问题：一方面，他们需要通过 最优 的行为来学习动作价值； 但另一方面，他们需要表现地不那么好，来探索所有的动作（来 找到 最优的动作）。 那么，如何既能够学到最优策略，又能够在实际中多探索呢？ 上一节的在策略方法实际上是一个妥协——它学习的并非最优策略，而是仍然保留了探索的近-最优策略。 一个更直截了当的方法是，使用两个策略，一个策略用来学习最优策略，另一个则更具探索性地用来产生行为。 用来学习的策略我们称之为 目标策略 ，另一个用来生成行为的称作 行为策略 。 这种情况下，我们说从数据中学习是“离开了（off）”目标策略的，整个过程用术语 离策略学习 表示。
> 
> 在策略方法一般来讲更简单一些，所以一般先考虑它。 离策略方法需要额外的概念和记号，且因为数据是由另一个不同的策略产生的，离策略方法通常拥有更大的方差，收敛更慢。 另一方面，离策略方法更加强大且更一般化。它包括在策略方法作为特殊情况，此时目标和行为策略相同。 离策略方法在应用程序中也有各种其他用途。例如，离策略能够从非传统学习器或人类专家生成的数据中学习。 离策略学习还被看成是学习多步预测模型的关键，该模型常被用来预测现实世界的动力学 （请看17.2章节; Sutton, 2009; Sutton et al., 2011）。