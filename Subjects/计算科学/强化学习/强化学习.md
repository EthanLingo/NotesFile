# 强化学习



# 笔记


强化学习基本框架：

![[Pasted image 20230210175316.png]]



## 分类

![[Pasted image 20220523202848.png]]



## 策略

对于策略，存在其方法。

策略方法包括：[[强化学习之策略评估]]、[[强化学习之策略改进]]；

[[强化学习之策略迭代]]是[[强化学习之策略评估]]与[[强化学习之策略改进]]双重交互过程。




优化策略方法包括：
- [[动态规划]]；
- [[强化学习之蒙特卡罗方法]]；

## 同轨策略学习 v.s. 离轨策略学习

根据是否评估策略与改进策略相同，分为[[强化学习之同轨策略学习]]（On policy）、[[强化学习之离轨策略学习]]（Off policy）。

## 状态值函数 v.s. 状态-动作值函数

根据策略函数分类为：[[强化学习之状态值函数]]、[[强化学习之状态-动作值函数]]

## 有模型学习 v.s. 无模型学习

根据有模型与无模型分类为：[[强化学习之基于模型学习]]、[[强化学习之无模型学习]]

## 强化学习之方法

相关的强化学习方法有：[[强化学习之蒙特卡罗方法]]、[[强化学习之时序差分学习]]、[[强化学习之SARSA方法]]、[[强化学习之Q-learning]]等

## 探索 v.s. 利用

[[辨析探索Exploration与利用Exploitation]]


在[[强化学习之基于表格型方法的规划和学习]]中，存在两种学习：[[强化学习之模型学习]]、[[强化学习之直接学习]]。






#### 来自MarginNote

![[人工智能_强化学习(2021-12-06-21-43-06).pdf]]



