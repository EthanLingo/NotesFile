#类型/教程

#知识 

#资料 

#来源/转载



[[宏观经济]]

[[DSGE]]

[[DSGE方法]]





## DSGE建模与编程（56）：贝叶斯估计（一）

许文立，安徽大学经济学院/CIMERS， cimers_dsge@econmod.cn



回复***DSGE\***查看往期所有推文。



很多人留言、发邮件问我，bayesian估计的一些问题，尤其是怎么入门贝叶斯估计。实际上，我们前面的DSGE建模与编程系列也有相关程序，可是大家“没时间”从头到尾看完，所以我今天就在专门讲讲DSGE的贝叶斯估计。今天只是贝叶斯估计的***入门实践篇***，后续还会有***理论篇***和***技巧篇\***。



前面内容几乎都是使用参数校准法。除此之外，我们还可以根据现实宏观经济数据来对DSGE模型参数进行估计。有许多方法可以估计DSGE模型参数：第一，矩匹配法（广义矩方法GMM的一种扩展），使用这种方法要求我们先声明一些目标矩，然后选择模型参数来匹配这些矩；第二，极大似然估计（ML），如果我们使用线性模型，我们就可以用Kalman滤波来近似给定数据下的似然函数（Kalman滤波允许我们从观测数据中推断不可观测的状态变量，从而得到观测数据下的似然函数）；第三，贝叶斯估计，这种方法就是在给定参数先验分布的情形下，最大化似然函数。需要注意的是，在经典统计理论中，参数是真实的，而数据是随机的，我们需要从数据中来推断参数；在贝叶斯统计中则恰好相反，参数随机的，数据是真实的。更详细的内容可以参考：[许文立，2018：](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455728214&idx=1&sn=79cd49d7edd9765bee3ac1e2680ee1ee&chksm=8cc0d0a3bbb759b5aa19530f302d2a275d0c2514660e5431023bc03b4876e4a121ae32e890bc&scene=21#wechat_redirect)[《关于DSGE模型的几点回应》](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455728214&idx=1&sn=79cd49d7edd9765bee3ac1e2680ee1ee&chksm=8cc0d0a3bbb759b5aa19530f302d2a275d0c2514660e5431023bc03b4876e4a121ae32e890bc&scene=21#wechat_redirect)。目前，最常用的估计方法是贝叶斯估计（Bayesian Estimation）。本节内容的目的在于Dynare 实践，因此，我们省略贝叶斯估计的技术性内容，如有兴趣可以关注后续推文。



估计DSGE模型的起点是数据。因此，我们在估计DSGE之前都要详细地描述所用数据，关于数据的分类，我们也不过多涉及。在贝叶斯估计过程中，我们必须要***确保观测变量的个数至多与模型冲击数相同\***。例如，一个DSGE模型中有6个冲击，那么，我们最多只能使用6 个观测变量的数据。前面使用的RBC模型中只有一个冲击——生产率冲击，因此，接下来的贝叶斯估计只选取了一个观测变量——GDP，时间为1992 年一季度-2017 年四季度。

![Image](640-20210302170406609)



贝叶斯估计的Dynare Code与前面的模拟程序大部分相似。也需要首先声明内生变量、外生变量和参数等。但是，需要注意的是，由于在贝叶斯估计时，DSGE模型中多了观测变量，因此，我们需要在声明内生变量时，也将观测变量写进去，例如，我们定义的观测变量为Y_obs，也就是说，除了在内生变量声明部分"var"后面增加Y_obs，其它部分与随机模型的code相同。



```octave
model;

[name = ’ 劳动供给方程’]
 Cˆ (siggma)*thetta*Nˆ (fi)=w;
[name = ’ 资本欧拉方程’]
C(1)ˆ (siggma)/Cˆ (siggma)=betta*(R(1)+(1-deltta));
[name = ’ 债券欧拉方程’]
C(1)ˆ (siggma)/Cˆ (siggma)=betta*(1+r);
[name = ’资本积累方程’]
K=I+(1-deltta)*K(-1);
[name = ’资本需求方程’]
R=alfa*A*K(-1)ˆ (alfa-1)*Nˆ (1-alfa);
[name = ’ 劳动需求方程’]
w=(1-alfa)*A*K(-1)ˆ (alfa)*Nˆ (-alfa);
[name = ’生产函数’]
Y=A*K(-1)ˆ (alfa)*Nˆ (1-alfa);
[name = ’资源总约束’]
Y=C+I;
[name = ’生产率冲击’]
A=A(-1)ˆ (rhoo)*exp(e a);
[name=’ 观测方程’]
Y obs=log(Y)-steady state(log(Y));
end;

```



接下来，就要编写贝叶斯估计特有的Dynare code了，即***声明观测变量***。Dynare必须要知道用于估计的观测变量。声明观测变量的语法结构是***varobs [var1 var2]***，同样以分号“**；**”结束。例如

varobs Y_obs;



接下来，就是声明初值。估计中的初值声明与模拟时一样。

![Image](640-20210302170611718)

再接下来，就是贝叶斯估计中最重要的步骤之一：***声明待估计参数的先验分布***。顾名思义，在这个模块，我们声明的是参数的分布，例如分布形式，分布的相关参数等等。一般的语法结构为

![Image](640-20210302170611881)

常用的先验分布如下

![Image](640-20210302170612295.jpeg)



表2.1中的$\mu$是先验均值（prior\_mean）；$\sigma$是先验标准误（prior\_standard\_error）；$p_3$是第三个参数（prior $3^{rd}$ parameter）默认值为0,；$p_4$是第四个参数（prior $4^{th}$ parameter）默认值为1。需要注意的是，当我们声明先验分布为均值分布(uniform\_pdf)时，分布的均值和标准误都为空，我们只需要声明第三、四个参数即可，例如，alfa, uniform\_form, , , 0, 1;。更多的先验分布信息，请参考Dynare手册。



在我们的案例中，我们选择生产率冲击的一阶自回归系数$\rho$作为估计参数，另一个需要估计的参数是生产率的外生冲击的方差。Dynare Code如下



- 
- 
- 
- 
- 
- 

```
estimated params;rhoo,beta pdf,0.72,0.05;stderr e a,inv gamma pdf,0.01,inf;end;
```

好了，现在万事俱备，只欠东风和下雨两件事了。为什么说是两件呢？且听我慢慢说来。



第一件事，也是最重要的事，肯定就是告诉Dynare执行参数估计。而执行参数估计要使用***estimation([option1,option2,option3,])[var1 var2……];\***。“**estimation**" 是触发dynare 来进行贝叶斯估计的命令，圆括号里需要选择一些选项，这些选项用逗号“，”隔开。如果我们想要贝叶斯估计之后得到一些图形结果，例如贝叶斯脉冲响应图，那么，我们可以在圆括号后面紧跟着输入我们想显示的内生变量名，也可以不输入。



那么，第二件事情就是估计命令中的选项“***options***"。估计命令中可选的项非常多，具体选项和功能可以参考Dynare手册。下面，我们介绍几种必备选项和最常用的选项。

![Image](640-20210302170612017.jpeg)



我们的案例的code如下：

- 
- 
- 

```
estimation(datafile=chap1_data,mode_compute=6,mh_replic=2000,mh_jscale=0.8,mode_check,bayesian_irf);
```



部分结果

![Image](640-20210302170612049.jpeg)



后验图：

![Image](640-20210302170611970)



## DSGE建模与编程（57）：贝叶斯估计理论篇

> 许文立，安徽大学经济学院/CIMERS，cimers_dsge@econmod.cn
> ~
> 在对话窗口回复**DSGE**，即可查看往期推文汇总。
> 如有问题或建议，请公众号留言或电子邮件我们。

前几天，我们向大家介绍了DSGE模型的贝叶斯（Bayesian）估计实践操作——。在Dynare手册中，estimation部分的选项可能是最多的，而且里面涉及到很多的算法，其中涉及到最多的两个字母可能就是**mh_**。今天，我们就给大家讲讲Bayesian，Gibbs和mh_都是什么鬼。

### 一、贝叶斯估计

我们要估计下列模型：
![Image](640-20210302170701217)
![Image](640-20210302170701088)

其中，![Image](640-20210302170701673.png)都是模型的（内生/观测）变量，e是外生变量/误差项，B是参数矩阵，sigma是标准差。
我们可能觉得上述方程就是一个回归方程，那好吧，我们暂且把它看作是回归分析，我们收集的T个数据，然后要估计系和扰动项的标准:
![Image](640-20210302170701089.png)
![Image](640-20210302170701101.png)

一旦我们知道了系数B和标准差sigma，我们就可以计算出统计量和显著水平，这个时候我们就可以对照临界值表找**星星（\**\*1%,\**5%,\*10%）**。


***而贝叶斯估计过程则完全不同于上述频率学派的参数估计过程。***贝叶斯估计过程通常为：
**第一步**：我们要给出待估参数![Image](https://mmbiz.qpic.cn/mmbiz_png/QA2ILNosZr4oTm4uTjwFNnayhTIBnqeGqIOGkKPAXITmHibkOoEHFZaKMaskhicvibJCedU4UTnoKDfOMKica1zssg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)的先验分布。先验分布与我们收集的数据X和Y无关，它们主要来源于研究者的经验和前期相关研究结果。例如，我们根据前人的研究可以得到B的先验分布：
![Image](640-20210302170701312)
其中表示先验均值，表示先验标准差。
**第二步**：我们收集关于X和Y的数据，写出上述模型的似然函数（likelihood function）：
![Image](640-20210302170701181)
**第三步**：利用第二步的似然函数来升级第一步的先验分布。即我们可以结合似然函数和先验分布来得到后验分布。
最后一步利用了贝叶斯法则：
![Image](640-20210302170701321.png)
但是，实践中，最困难的地方在于要对条件分布积分来计算边际后验分布：
![Image](640-20210302170701201)
![Image](640-20210302170701288.png)

### 二、Gibbs抽样

Gibbs抽样极大的简化了上述积分过程，从而使得贝叶斯分析得到非常广泛地运用。
Gibbs抽样是一种数值技术，其从条件分布中抽样来近似联合分布和边际分布。
假设k个变量的联合后验分布
![Image](640-20210302170701290)
假设条件分布![Image](640-20210302170701339)是已知的，那么，Gibbs抽样算法来获得边际分布的近似分布：
**第一步**：设立初始值：
![Image](640-20210302170701366)

**第二步**：从条件分布中得的第一次抽样样本x11:
![Image](640-20210302170701383.png)
重复第二步，依次得到![Image](640-20210302170701484.png)的第一次抽样样本![Image](640-20210302170701359.png)

**第三步**：将![Image](640-20210302170701422.png)作为第二次抽样的初始值，在重复上述抽样。
随着上述Gibbs抽样次数趋向于无穷，来自于条件分布的抽样将会收敛的联合/边际分布。
换言之，我们只要重复M次Gibbs抽样，并保留最后H次抽样，那么，我们就可以的边际后验分布均值/模的估计值写成
![Image](640-20210302170701397.png)

### 三、MH算法

MH算法就是Metropolis Hastings算法。而MH算法是上述Gibbs算法的一般化。上述Gibbs算法并不适用于DSGE模型，因为它依赖于条件分布已知的情况。而在DSGE模型中，许多参数的条件后验分布并可用。而MH算法则是用于这种情形来近似联合/边际后验分布。因此，我们才会在Dynare中见到那么多的mh命令。

假设我们现在要从下列分布中抽样：
![Image](640-20210302170701448)B是参数集。![Image](640-20210302170701500.png)是后验分布，由于它不可用，我们不能直接从这个分布中抽样。
在这种情形下，MH算法如下：
**第一步**：申明一个候选的密度函数![Image](640-20210302170701531-4676021.)，其中，G表示参数B的抽样。
**第二步**：从上述候选密度函数中抽样参数![Image](640-20210302170701459.png)的一个候选值。
**第三步**：计算接受![Image](https://mmbiz.qpic.cn/mmbiz_png/QA2ILNosZr4oTm4uTjwFNnayhTIBnqeG2a3vgMjsI3T0tDdnfVhDRJzttUVgqSqrdJHbRg6BUY0YryvTflAAvg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)的概率a:
![Image](640-20210302170701531)

**第四步**：如果接受a足够大，就保留抽样参数![Image](640-20210302170702329.png)，否则就保留旧参数![Image](640-20210302170701600)。 
**第五步**：重复2-4步M次，然后保留最后的H次，基于最后保留的H次抽样来进行参数推断。

我们可能对于MH算法还有许多疑问，第一个问题可能就是如何声明**候选的密度函数![Image](640-20210302170701531-4676021.)**?
（1）随机游走MH算法
顾名思义，将密度函数声明为一个随机游走过程
![Image](640-20210302170701566)
其中![Image](640-20210302170701585)，因为![Image](640-20210302170701727)，且是一个正态分布，具有对称性，所以![Image](640-20210302170701661.png)，那么，上述MH算法的第二步中的接受率可以化简为
![Image](640-20210302170701719)
那么，随机游走MH算法的步骤为：
**第一步**：申明初值B0和冲击的方差sigma0；
**第二步**：从随机游走过程中抽样出新的参数：
![Image](640-20210302170701752)
**第三步**：计算接受率
![Image](640-20210302170701698.png)
**第四步**:重复2-3步M次，并留下最后H次进行推断。

**注意：Sigma**是我们自己设定的，Sigma越大，接受率越低，但是这意味着MH算法可以在更大的参数空间中抽样，反之亦然。一般来看，我们应该调节Sigma来使得接受率a在20%-40%之间。

> 熟悉Dynare手册的人可能立马就会想起来，estimation选项里有一个mh_jscale。且手册中说，必须调节这个选项的值来使得接受率在25%-33%之间。实际上，mh_jscale就是调节冲击方差Sigma的一个调节因子。
> ~
> 且在Dynare中，mh_replic就是声明MH算法的抽样次数M。mh_drop就是申明抽样中被放弃的比例，也就是![Image](640-20210302170701805.png)。



PDF版本可发邮件或留言索要，可以登录“量化经济分析平台”（www.econmod.cn）下载。



## DSGE建模与编程（59）：贝叶斯估计（三）技巧篇1



前面，我们已经向大家介绍过贝叶斯估计的实践篇——[DSGE建模与编程（56）：贝叶斯估计（一）](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729440&idx=1&sn=c4fd86e7e9ffb0daca97d391eca5f71b&chksm=8cc0d5d5bbb75cc35161fd25e283dff51790f038fddfd44f2d668fe7a4ec830844e7f27c1309&scene=21#wechat_redirect)和理论篇——[DSGE建模与编程（57）：贝叶斯估计（二）](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729616&idx=1&sn=50e1fc65f5cd0235e72744fa245bb17f&chksm=8cc0d525bbb75c332c2fee2a958ab0f44fba0de787d16983740f3e38ab84499fa2d165209d06&scene=21#wechat_redirect)，实际上，还有参数识别检验也很重要——[DSGE建模与编程（58）：Dynare参数识别检验](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729623&idx=1&sn=f2736482f57b2b7c35acc1dd38ceed63&chksm=8cc0d522bbb75c34ae427b37a0fd8c90d224ec6dc7c58de959a4fffa9a88d8814ebd8eeb4a94&scene=21#wechat_redirect)。



今天就完成DSGE贝叶斯估计三部曲技巧篇的***前半部分\***。



如果做过贝叶斯估计的朋友们可能知道，贝叶斯估计在code中分成三大模块：

```octave
% 模块一：模型部分的测量方程
model;
……
[name='测量方程']
Y_obs=Y-steady_state(Y);

end;

%模块二：估计参数的先验分布
estimated_params;
……
end;

%模块三：估计命令

estimation(options)[varnames];
```



如果上述code完成后，会出来很多贝叶斯估计图和估计结果，包括诊断信息等。今天，我们先给大家介绍先验分布和估计命令的有用技巧。



**一、先验分布的选择技巧**



在贝叶斯估计过程中，关于估计参数的先验分布选择，有许多经验法则。一般来说，我们可以将参数划分为三种类型（参见Del Negro and Schorfheide（2008）、Herbst and Schorfheide（2015））：1）第一组包含影响DSGE模型稳态的参数；2）第二组包含那些刻画了外生冲击过程的运动法则；3）第三组包含那些不影响模型稳态，但却控制了内生传导机制的参数。

在将参数集划分成上述三种类型后，我们就可以考虑这些参数的合理先验区间。实践中，

​    1） 我们通常利用样本期之前的平均值来得到影响稳态的参数先验分布；

​    2） 第三组参数则要利用微观计量证据来声明先验分布；

​    3） 第二组参数通常不可观测，因此其先验分布也最难以设定。但Herbst and Schorfheide（2015）给出了一种迭代过程来获得它们的先验分布：1.设定先验分布；2.从该先验分布中提取抽样；3.根据DSGE模型模拟生产变量数据，利用模拟轨迹计算样本矩；4.评价样本矩的先验分布的合理性；5.调整先验分布，直到样本矩先验分布与先验信念一致。

通常根据参数定义域来选择分布。例如，如果参数定义域为实数域，先验分布可以选择正态分布；如果参数定义域为非负，先验分布可以选择对数正态分布、伽马分布或者逆伽马分布；如果参数定义域有有界区间，先验分布可以为截断正态分布或贝塔分布。E. Sims（2017）给出的经验法则是，如果参数在[0,1]，用贝塔分布；对于冲击的标准差，用拟伽马分布；而另外一些参数，要么用正态分布，要么用伽马分布。

最为重要的是，这些先验分布可能有些随意，并带有主观性，因此，我们一定要做敏感性测试。这也是大部分好的DSGE文献所必备的内容。



**二、估计命令中mode_compute最优化算法技巧**



​    在estimation命令中，可能最重要的就是mode_compute最优化算法的选择。而且，我们会发现，在初次选择模算法时，dynare会非常敏感，经常会报错。我们在CIMERS Seminar中建议大家一定要使用不同算法来计算模，从理论来讲，相同的数据集，即使是不同的算法也会最终收敛到相同的后验模。那么，我们今天就向大家推荐一个mode_compute的循环命令：

```octave
%****************************************************************
%========================================================
% Find posterior mode provided by Reuben Punnoose Jacob
%========================================================


optimtypevals=[4 7 1 6]; % Declare types of Dynare optimisers used
 
   
for jj=1:length(optimtypevals)
        stropt=optimtypevals(jj);
        if optimtypevals(jj)==4,     disp('RUNNING OPTIMISER-TYPE: Sims');
        elseif optimtypevals(jj)==2, disp('RUNNING OPTIMISER-TYPE: Simulated annealing'); 
        elseif optimtypevals(jj)==1, disp('RUNNING OPTIMISER-TYPE: Matlab fmincon');           
        elseif optimtypevals(jj)==5, disp('RUNNING OPTIMISER-TYPE: Marco Ratto optimiser');  
        elseif optimtypevals(jj)==7, disp('RUNNING OPTIMISER-TYPE: fminsearch');  
        elseif optimtypevals(jj)==6, disp('RUNNING OPTIMISER-TYPE: Dynare Monte Carlo');  
        elseif optimtypevals(jj)==8, disp('RUNNING OPTIMISER-TYPE: Nelson-Mead Simplex');
        end
        options_.console_mode=1;
        options_.nograph=1; % Suppress graphs
        options_.silent_optimizer=1;% Suppress display of optimisation
        options_.cova_compute=0;% Do not compute std errors of parameter estimates
        options_.plot_priors=0;% Suppress prior plots
        options_.mh_replic= 0;% No MCMC
        options_.noprint=1;
        options_.lik_init=1;
        if jj==1
            eval(['options_.mode_compute=' num2str(stropt) ';']) ;
            estimation(datafile= chap2_data,optim=('MaxIter',500)); 
            movefile([M_.fname '_mode.mat'], 'newmode.mat'); % rename mode file
            
        elseif jj>1 && jj<length(optimtypevals) 
            eval(['options_.mode_compute=' num2str(stropt) ';']) ;
            estimation(mode_file=newmode,datafile= chap2_data,optim=('MaxIter',5000));  
            movefile([M_.fname '_mode.mat'], 'newmode.mat'); % rename mode file
        
        elseif jj==length(optimtypevals)
            eval(['options_.mode_compute=' num2str(stropt) ';']) ;
            
            options_.gmhmaxlik.target=0.2;
            options_.gmhmaxlik.iterations = 1; % [default=3] to call repeatedly the new optimization routine. Improves the estimates of the posterior covariance matrix and of the posterior mode.
            options_.gmhmaxlik.number = 100000; %[default=20000] to set the number of simulations used in estimation of the covariance matrix.
            options_.gmhmaxlik.nscale = 200000; % [default=200000] to set the number of simulations used in the tuning of the scale parameter.
            options_.gmhmaxlik.nclimb = 200000; % [default=200000] to set the number of simulations used in the hill climbing simulations.

            estimation(mode_file=newmode,datafile= chap2_data, cova_compute=1);  
            movefile([M_.fname '_mode.mat'], 'finalmode.mat'); % rename mode file
        
        end
end
```



上述程序将会自动依次执行模最优化算法：4,7,1,6。每一次计算的模都会保存起来，然后下一次最优化算法会调用上一次结果，从而得到更好的后验模估计。



   需要注意的是，大家只需要修改estimation中的数据文件名即可，并加入一些各位想要看到的输出结果选项。



***注：完整的code案例，请上“量化经济分析平台”（www.econmod.cn）免费获取。\***





## DSGE建模与编程(68)：贝叶斯估计（四）—SMC



前面，我们已经向大家介绍过贝叶斯估计的实践篇——[DSGE建模与编程（56）：贝叶斯估计（一）](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729440&idx=1&sn=c4fd86e7e9ffb0daca97d391eca5f71b&chksm=8cc0d5d5bbb75cc35161fd25e283dff51790f038fddfd44f2d668fe7a4ec830844e7f27c1309&scene=21#wechat_redirect)、理论篇——[DSGE建模与编程（57）：贝叶斯估计（二）](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729616&idx=1&sn=50e1fc65f5cd0235e72744fa245bb17f&chksm=8cc0d525bbb75c332c2fee2a958ab0f44fba0de787d16983740f3e38ab84499fa2d165209d06&scene=21#wechat_redirect)和技巧篇——[DSGE建模与编程（59）：贝叶斯估计（三）技巧篇1](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729649&idx=1&sn=c50f2cf30ac0a85e89784336e6976e5b&chksm=8cc0d504bbb75c12886e8936c0b42fc9de4d3982dde1fd0f9c91d0793ff91fced646980e4bce&scene=21#wechat_redirect)。实际上，还有参数识别检验也很重要——[DSGE建模与编程（58）：Dynare参数识别检验](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729623&idx=1&sn=f2736482f57b2b7c35acc1dd38ceed63&chksm=8cc0d522bbb75c34ae427b37a0fd8c90d224ec6dc7c58de959a4fffa9a88d8814ebd8eeb4a94&scene=21#wechat_redirect)。



今天，我给大家介绍一下用于非线性DSGE模型贝叶斯推断的一种前沿算法——粒子滤波（PF）/次序蒙特卡洛（SMC）算法。



各位可能都看过Fernandez-Villaverde and Rubio-Ramırez (2007，RES)用粒子滤波PF估计DSGE的文章。也在Herbst and Schorfheide (2015)的书第四章看过次序蒙特卡洛SMC算法及相关应用的例子。下面，基于Cai et al.（2019）的“Online Etimation of DSGE Model”和Fernandez-Villaverde and Rubio-Ramırez （2004）的“Sequential Monte Carlo Filtering: an Example”来向大家介绍一下PF/SMC。



粒子滤波是一种蒙特卡洛方法，用于贝叶斯推断——非线性、非高斯随机过程的似然函数评估。Doucet and Johansen（2008，“A Tutorial on Particle Filtering and Smoothing: Fifteen years later”）指出，自从1993年提出粒子滤波以来，所有粒子滤波的基础、高级方法都可以重新用次序蒙特卡洛SMC算法来表示。



MH-MCMC和SMC的差异



DSGE模型的估计本来就是一项复杂的任务。随着模型开始融入异质性、ZLB或OBC等非线性结构，它们开始变得更加复杂，更加难以估计。目前，常用的估计算法并不胜任这一新的挑战。



贝叶斯估计是DSGE模型最主要的参数估计方法。为了实现贝叶斯估计，研究者需要将其对模型参数的初始认知以一个概率分布的形式（称为“先验”）来表示，然后利用观测到的时间序列数据来升级这个概率分布。升级后的概率分布称为“后验”。实践中，从后验分布中产生随机样本是非常麻烦的事情。



目前，最广泛使用的方法称为“RWMH算法”（参见理论篇——[DSGE建模与编程（57）：贝叶斯估计（二）](http://mp.weixin.qq.com/s?__biz=MzAwODY5MDA3NA==&mid=2455729616&idx=1&sn=50e1fc65f5cd0235e72744fa245bb17f&chksm=8cc0d525bbb75c332c2fee2a958ab0f44fba0de787d16983740f3e38ab84499fa2d165209d06&scene=21#wechat_redirect)），例如，Dynare。虽然，RWMH算法是过去20多年贝叶斯宏观经济计量学的基本方法，但是在应用中，它存在两个不容忽视的缺陷。



第一，速度慢，不能发挥目前并行计算的优势。直观上来看，MH算法让一个粒子（即是一个向量包含所有模型参数）遍历整个参数空间，这在高后验概率区域更耗时。该算法在这个过程中要追踪所有参数值，然后把信息反馈给用户。



由于一个粒子是依次运动的，且我们并不知道其方向（毕竟是随机游走过程），因此，我们并不能得到一个前端，以便用于下一次计算的起点。这种限制对于单纯功能的DSGE模型来说几乎可以忽略不计。但是，如果我们想要估计一个更为复杂的模型（例如异质性代理人），可能我们需要等计算机运行几个月。



SMC算法改变了这场游戏：我们并不需要发送单一粒子来遍历整个参数空间的所有值，相反，我们可以发送数千个粒子，让每个粒子都只遍历一个非常短的距离。这有什么优势呢？每个粒子都有自己独立的运动方向。这就意味着如果我们的并行计算系统中有许多处理器，那么，我们就可以将每个粒子分配给一个处理器，然后，让它们同时遍历更小的参数空间。而且，由于现在每个粒子都只运动更短的距离，那么，上述需要花费数个月完成的计算可能在数小时内就能完成（注意：由于我们有很多粒子，因此完整的后验也可以很好的估计）。这种方法在统计学文献中十分流行，但是最近才应用到宏观经济计量学中例如，Cai et al.（2019）和Herbst and Schorfheide（2015）等。



MH算法的第二个缺陷是，只要我们的数据更新了，或者我们稍微修正了一下模型，那么，我们就需要重新开始估计过程。如果我们在利用模型进行预测，MH算法的这个特性非常让人恼火。我们想象一下，如果现在数据更新到2019年第二季度了，那么，我们需要将模型估计也更新到第二季度。但是，我们从2019年第一季度得到的估计粒子束可能对于最新数据得到的后验分布来说仍然是一个非常好的近似。那么，在数据更新到最新季度之后，MH算法一切都要重头开始，你说是不是很恼火。不用担心，SMC提供了一个更有效率的估计方式：我们并不需要重头开始，我们仅仅需要初始化上一季度得到的粒子，让它们再往前运动更长一段距离，从而得到新的后验分布。***也就是说，我们更新数据，估计模型的过程就像徒步探险旅程。\******我们穿着SMC装备，当走到未开发区域时，我们就要停下来，派先遣队员去“杀出一条”路，待新路出来后，我们只需要从“歇息点”整装出发即可，不需要像MH算法那样从头走一遍\***。所以，Cai et al.(2019)将这个过程称为“***DSGE模型的‘联机’估计***”。（注：对Matlab的系统控制工具箱熟悉的话，对“online estimation”就不会陌生了）





SMC估计的例子，以后再给出，敬请关注！

上述引用文献及SMC主要资料请去“量化经济分析”（www.econmod.cn）论坛下载！





